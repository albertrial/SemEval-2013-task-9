{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AHLT - First delivery - Task 9.1 NERC\n",
    "**Albert Rial**   \n",
    "**Karen Lliguin**   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This delivery consists of solving the task 9.1 of the SemEval-2013 challenge. The task concerns the named entity recognition and classification of drug names.  \n",
    "\n",
    "The dataset provided contains XML files with sentences and the entities appearing on it and their corresponding type. There are four general types: drug, brand, group and drug_n. The data is already splitted in three subsets: Train, Devel and Test.\n",
    "\n",
    "We are also provided with some external resources containing knowledge extracted from other databases (DrugBank, HSDB) and with evaluation scripts.\n",
    "\n",
    "To do so, we use different methods and resources and we divide the task in different subtasks/goals.\n",
    "\n",
    "Note: in this notebook we only show and comment the relevant parts of our code, the ones asked on the delivery, to avoid having a very long. To see all our code you can go to the folder *Project*. There is a notebook for each goal and are prepared to be run and extract the same results shown in this report. In that folder you can also find the evaluator outputs of each goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal 1: Rule-based, no external knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "First, we develop a simple rule-based baseline system to carry out the task. In this first version we only use the information from the Train dataset and we do not use external knowledge. \n",
    "\n",
    "With this we want to achieve an overall F1 score of at least 0.5 on the Devel dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration\n",
    "To do this system, first we do a data exploration to know which common characteristics have the drugs in each type.\n",
    "\n",
    "Given only the Train dataset, we analyze the following aspects:\n",
    "- The most common words that appear after and before each type of drug.\n",
    "- The most common prefixes and sufixes of each type of drug (given different number of characters).\n",
    "- The most common drug entities of each type.\n",
    "    \n",
    "You can find the full code of the data exploration in the jupyter notebook called *Data_Exploration.ipynb*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details\n",
    "The main function of our system is *extract_entities(tokens)*, where, given a list with the tokens of a sentence and taking into account the rules defined, we return a list of the entities we found and their type.\n",
    "\n",
    "Basically we loop over all the tokens and using the following rules we try to recognize and classify the drugs appearing. The rules are:\n",
    "- Sufixes and prefixes: we use the most common prefixes and sufixes found on the data exploration for each type of drug. If we find a word with an specific prefix or sufix that is in our list of common prefixes and sufixes of a type, we consider the word as an entity and we classify it in the corresponding type.\n",
    "- For the types drug_n and brand we also check if the word is uppercase. If is uppercase and the length is greater than 4, we classify the word as brand. Otherwise, if the word is uppercase and the length is less or equal than 4, we classify it as drug_n.\n",
    "- As in data exploration we observed that type group contained several drug names formed by two words, we add a rule taking care of checking whether two consequent words are classified as drug, in order to distinguish this type of drug names. \n",
    "- As drug_n still showed a low F1 score, a rule checking whether the word contain the character \"-\" or digits is added, as from the previous analysis this pattern was observed in the names of the drugs of that partucular type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(tokens):\n",
    "    entities = [] # Output list of entities\n",
    "    prev_drug = \"\" # Previous drug found (if any)\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        token = tokens[i]\n",
    "        word = token[0]\n",
    "        \n",
    "        # Prefix and sufix rules\n",
    "        drug_prefixes = ('pheny', 'digox', 'warfa', 'meth', 'theophy', 'lith', 'keto', 'cime', 'insu', 'fluox', 'alcoh', 'cyclos', 'eryth', 'carba', 'rifa', 'caffe')\n",
    "        drug_sufixes = ('pitant', 'dine', 'azole', 'mide', 'pine', 'line', 'mine', 'tine', 'arin', 'avir', 'azem', 'rine', 'rone', 'arbital', 'olol', 'afil', 'inol', 'zolam')\n",
    "        \n",
    "        group_prefixes = ('benzo', 'beta', 'antico', 'antide', 'antibi', 'antihi', 'nsai', 'contra')\n",
    "        group_sufixes = ('steroids','tics', 'ants', 'ents', 'tors', 'acid', 'acids', 'ceptives', 'gens', 'pines', 'lines', 'mines')\n",
    "        \n",
    "        brand_prefixes = ('aspi', 'accu', 'beza', 'star', 'exja')\n",
    "        brand_sufixes = ('tane', 'dine', 'anil')\n",
    "        \n",
    "        drug_n_prefixes = ('ibog', 'endo')\n",
    "        drug_n_sufixes = ('ate', 'sin', 'toxin', 'orfon')\n",
    "        \n",
    "        # Rules for drug type\n",
    "        if word.lower().startswith(drug_prefixes) or word.lower().endswith(drug_sufixes):\n",
    "            entities.append({'name':word, 'offset': str(token[1])+'-'+str(token[2]),'type':'drug'})\n",
    "            prev_drug = str(word)+ \" \"+str(token[1])+\" \"+\"drug\"\n",
    "        \n",
    "        # Rules for group type\n",
    "        elif word.lower().startswith(group_prefixes) or word.lower().endswith(group_sufixes):\n",
    "            if prev_drug != '':\n",
    "                info = prev_drug.split(\" \")\n",
    "                if len(entities) > 0 and info[2]=='group':\n",
    "                    entities.pop()\n",
    "                    entities.append({'name':str(info[0])+word, 'offset': str(info[1])+'-'+str(token[2]),'type':'group'})\n",
    "            else:\n",
    "                entities.append({'name':word, 'offset': str(token[1])+'-'+str(token[2]),'type':'group'})\n",
    "            prev_drug = str(word)+ \" \"+str(token[1])+ \" \"+\"group\"\n",
    "        \n",
    "        # Rules for brand type\n",
    "        elif (word.isupper() and len(word)>4) or word.lower().startswith(brand_prefixes) or word.lower().endswith(brand_sufixes):\n",
    "            entities.append({'name':word, 'offset': str(token[1])+'-'+str(token[2]),'type':'brand'})\n",
    "            prev_drug = str(word)+ \" \"+str(token[1])+ \" \"+ \"brand\"\n",
    "        \n",
    "        # Rules for drug_n type\n",
    "        elif word.isupper() or word.lower().startswith(drug_n_prefixes) or word.lower().endswith(drug_n_prefixes)\\\n",
    "        or (bool(re.search(r'\\d', word)) and '-' in word):\n",
    "            entities.append({'name':word, 'offset': str(token[1])+'-'+str(token[2]),'type':'drug_n'})\n",
    "            prev_drug = str(word)+ \" \"+str(token[1])+ \" \"+\"drug_n\"\n",
    "            \n",
    "        else:\n",
    "            prev_drug = \"\"\n",
    "        \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "#### Devel\n",
    "\n",
    "(The results of the analysis are contaied in the notebook _data_exploration_ on the Apendix folder)\n",
    "\n",
    "```\n",
    "The evaluator output for this version on devel is shown below\n",
    "\n",
    "SCORES FOR THE GROUP: develGoal1 RUN=1\n",
    "\n",
    "Strict matching (boundaries + type)\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "773\t292\t0\t706\t496\t1771\t0.5\t0.44\t0.46\n",
    "\n",
    "\n",
    "\n",
    "Exact matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "815\t250\t0\t706\t496\t1771\t0.52\t0.46\t0.49\n",
    "\n",
    "\n",
    "\n",
    "Partial matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "815\t0\t250\t706\t496\t1771\t0.52\t0.53\t0.53\n",
    "\n",
    "\n",
    "\n",
    "type matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "904\t161\t0\t706\t496\t1771\t0.58\t0.51\t0.54\n",
    "\n",
    "\n",
    "\n",
    "SCORES FOR ENTITY TYPE\n",
    "Exact matching on drug\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "511\t14\t0\t520\t45\t1045\t0.9\t0.49\t0.63\n",
    "\n",
    "\n",
    "Exact matching on brand\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "115\t0\t0\t65\t25\t180\t0.82\t0.64\t0.72\n",
    "\n",
    "\n",
    "Exact matching on group\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "120\t117\t0\t217\t83\t454\t0.38\t0.26\t0.31\n",
    "\n",
    "\n",
    "Exact matching on drug_n\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "27\t0\t0\t65\t33\t92\t0.45\t0.29\t0.36\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "P\tR\tF1\n",
    "0.64\t0.42\t0.5\n",
    "```\n",
    "\n",
    "#### Test\n",
    "\n",
    "The evaluator output for this version on test is shown below\n",
    "\n",
    "```\n",
    "SCORES FOR THE GROUP: testGoal1 RUN=1\n",
    "\n",
    "Strict matching (boundaries + type)\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "214\t109\t0\t363\t331\t686\t0.33\t0.31\t0.32\n",
    "\n",
    "\n",
    "\n",
    "Exact matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "242\t81\t0\t363\t331\t686\t0.37\t0.35\t0.36\n",
    "\n",
    "\n",
    "\n",
    "Partial matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "242\t0\t81\t363\t331\t686\t0.37\t0.41\t0.39\n",
    "\n",
    "\n",
    "\n",
    "type matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "252\t71\t0\t363\t331\t686\t0.39\t0.37\t0.38\n",
    "\n",
    "\n",
    "\n",
    "SCORES FOR ENTITY TYPE\n",
    "Exact matching on drug\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "124\t8\t0\t219\t31\t351\t0.76\t0.35\t0.48\n",
    "\n",
    "\n",
    "Exact matching on brand\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "26\t0\t0\t33\t1\t59\t0.96\t0.44\t0.6\n",
    "\n",
    "\n",
    "Exact matching on group\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "49\t16\t0\t90\t48\t155\t0.43\t0.32\t0.37\n",
    "\n",
    "\n",
    "Exact matching on drug_n\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "15\t15\t0\t91\t34\t121\t0.23\t0.12\t0.16\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "P\tR\tF1\n",
    "0.6\t0.31\t0.4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "The final results obtained are:\n",
    "\n",
    "**Devel: precision 0.64, recall 0.42, F1 0.5**\n",
    "\n",
    "**Test: precision 0.6, recall 0.31, F1 0.4**\n",
    "\n",
    "From the results it can be observed that this approach of trying to infer general rules that work with our data is not the best one. It can be noticed that for each type of drug, the precision is much more higher than the recall. This means that with this approach most of the words that are actually drugs are missed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal 2 : Rule-based, using external knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Once accomplished the first goal we use the rule-based system defined but also using information from external knowledge sources.\n",
    "\n",
    "The goal is to obtain a F1 score of at least 0.6 on the Devel dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details\n",
    "The most part of the code is reused from the first approach. The only modifications done are:\n",
    "- extract_drug_bank(drug_bank_path): function where we read the DrugBank dataset and we store in a dictionary the drug name and the drug type given by the external dataset.\n",
    "- extract_entities(tokens): for each word we do:\n",
    "    - First, we check if the word is inside the DrugBank dataset. If it exists there, we classify it according to the type specified by the DrugBank.\n",
    "    - If it is not present, we check the drug_n rules that we had in our first approach. We do this because there is not any drug_n inside the DrugBank and is the class with worst F1 score.\n",
    "    - Finally, as a lot of drug names inside the DrugBank have more than one word, we check if the union of the word and its previous words appear in the DrugBank. In case they appear there, we add all the words as a single entity and with the corresponding type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_drug_bank(drug_bank_path):\n",
    "    drug_bank = {}\n",
    "    with open(drug_bank_path, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            data = line.strip().split('|')\n",
    "            drug_name = data[0]\n",
    "            drug_type = data[1]\n",
    "            drug_bank[drug_name.lower()] = drug_type\n",
    "    return drug_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(tokens):\n",
    "    entities = []\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        token = tokens[i]\n",
    "        word = token[0]\n",
    "        \n",
    "        drug_n_prefixes = ('18-m', 'ibog', 'endo', 'toxi')\n",
    "        drug_n_sufixes = ('ine', 'ate', '8-mc', 'sin', 'xin', 'pge2', 'mhd')\n",
    "        \n",
    "        # Check if single word is in bank\n",
    "        if word.lower() in drug_bank:\n",
    "            entities.append({'name':word, 'offset': str(token[1])+'-'+str(token[2]),'type':drug_bank[word.lower()]})\n",
    "        \n",
    "        # Check drug_n rules\n",
    "        elif word.isupper() or word.lower().startswith(drug_n_prefixes) or word.lower().endswith(drug_n_prefixes):\n",
    "            entities.append({'name':word, 'offset': str(token[1])+'-'+str(token[2]),'type':'drug_n'})\n",
    "        \n",
    "        # Check if multiple consecutive words appear in the drug bank as a single drug\n",
    "        else:\n",
    "            for j in range(1, 5):\n",
    "                if i>=j-1:\n",
    "                    words_joined  = ' '.join([t[0] for t in tokens[i-j:i+1]])   \n",
    "                    if words_joined.lower() in drug_bank:\n",
    "                        entities.append({'name':words_joined, 'offset': str(tokens[i-j][1])+'-'+str(tokens[i][2]),'type':drug_bank[words_joined.lower()]})\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "#### Devel\n",
    "```\n",
    "SCORES FOR THE GROUP: develGoal2 RUN=1\n",
    "\n",
    "Strict matching (boundaries + type)\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1177\t350\t0\t244\t524\t1771\t0.57\t0.66\t0.62\n",
    "\n",
    "\n",
    "\n",
    "Exact matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1270\t257\t0\t244\t524\t1771\t0.62\t0.72\t0.66\n",
    "\n",
    "\n",
    "\n",
    "Partial matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1270\t0\t257\t244\t524\t1771\t0.62\t0.79\t0.69\n",
    "\n",
    "\n",
    "\n",
    "type matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1291\t236\t0\t244\t524\t1771\t0.63\t0.73\t0.68\n",
    "\n",
    "\n",
    "\n",
    "SCORES FOR ENTITY TYPE\n",
    "Exact matching on drug\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "866\t44\t0\t135\t76\t1045\t0.88\t0.83\t0.85\n",
    "\n",
    "\n",
    "Exact matching on brand\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "170\t3\t0\t7\t32\t180\t0.83\t0.94\t0.88\n",
    "\n",
    "\n",
    "Exact matching on group\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "115\t52\t0\t287\t52\t454\t0.53\t0.25\t0.34\n",
    "\n",
    "\n",
    "Exact matching on drug_n\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "26\t15\t0\t51\t37\t92\t0.33\t0.28\t0.31\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "P\tR\tF1\n",
    "0.64\t0.58\t0.6\n",
    "```\n",
    "\n",
    "### Test\n",
    "```\n",
    "SCORES FOR THE GROUP: testGoal2 RUN=1\n",
    "\n",
    "Strict matching (boundaries + type)\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "401\t160\t0\t125\t334\t686\t0.45\t0.58\t0.51\n",
    "\n",
    "\n",
    "\n",
    "Exact matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "482\t79\t0\t125\t334\t686\t0.54\t0.7\t0.61\n",
    "\n",
    "\n",
    "\n",
    "Partial matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "482\t0\t79\t125\t334\t686\t0.54\t0.76\t0.63\n",
    "\n",
    "\n",
    "\n",
    "type matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "439\t122\t0\t125\t334\t686\t0.49\t0.64\t0.56\n",
    "\n",
    "\n",
    "\n",
    "SCORES FOR ENTITY TYPE\n",
    "Exact matching on drug\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "299\t18\t0\t34\t62\t351\t0.79\t0.85\t0.82\n",
    "\n",
    "\n",
    "Exact matching on brand\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "50\t4\t0\t5\t8\t59\t0.81\t0.85\t0.83\n",
    "\n",
    "\n",
    "Exact matching on group\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "41\t10\t0\t104\t21\t155\t0.57\t0.26\t0.36\n",
    "\n",
    "\n",
    "Exact matching on drug_n\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "11\t6\t0\t104\t31\t121\t0.23\t0.09\t0.13\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "P\tR\tF1\n",
    "0.6\t0.51\t0.53\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "The final result obtained are:\n",
    "\n",
    "**Devel: precision 0.64, recall 0.58, F1 0.6** \n",
    "\n",
    "**Test: precision 0.6, recall 0.51, F1 0.53**\n",
    "\n",
    "The results obtained by using external resources show that they especially help to identify the types of drugs brand and drug. For this reason in those types the recall value is higher than the precistion(in general). This is shown an increasing of the F1 value on those brands while the other two remain almost equal. As this external resources only helps to one part of the drug types, the NERC system is unable to generalize properly and keeps behaving poorly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal 3 : ML, no external knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "After trying a rule-based system and viewing its limitations, in this goal we try to solve the same problem (NERC) using machine learning techniques.\n",
    "\n",
    "Specifically we use a CRF model to solve the task. We do the following steps:\n",
    "- Extract and define different features to encode the data.\n",
    "- Train and tune a model with the obtained feature vectors of the Train dataset.\n",
    "- Test the model using Devel and Test datasets.\n",
    "\n",
    "In this goal we try to achieve an overall F1 score of at least 0.6 on Devel dataset using only information from the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration\n",
    "To do this system, we reused the data exploration done on the first goal and we defined most of the features based on that. In the next section we will detail all the features used (the ones finally used and the ones tested but discarded)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details\n",
    "In the following function *extract_features(tokens, pos_tag)* we receive the tokens of a sentence and their POS tag, and we extract different features to encode the data.\n",
    "\n",
    "The features defined are:\n",
    "- Word in lowercase\n",
    "- Prefixes and sufixes (from 2 characters to 5)\n",
    "- Word length\n",
    "- POS tag of the word\n",
    "- First character of the POS tag\n",
    "- Booleans indicating if the word is uppercase, if contains uppercase and lowercase characters, if contains digits, if contains dash, if is only composed by letters and if is title.\n",
    "\n",
    "Other features have been tested but it have been discarded because they were not improving the performance. Some of them are:\n",
    "- Booleans indicating if the word is a punctuation, if contains special characters and if it starts with a digit.\n",
    "- Similar features as the ones above but with information about the previous and next word (previous and next word in lowercase, length of both, their POS tag, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tokens, pos_tag):\n",
    "    features = []\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        token = tokens[i]\n",
    "        word = token[0]\n",
    "        \n",
    "        lower = re.compile(r'.*[a-z]+')\n",
    "        upper = re.compile(r'.*[A-Z]+')\n",
    "        \n",
    "        feature_vector = [\n",
    "            'word.lower=' + word.lower(),\n",
    "            'word[-5:]=' + word[-5:],\n",
    "            'word[-4:]=' + word[-4:],\n",
    "            'word[-3:]=' + word[-3:],\n",
    "            'word[-2:]=' + word[-2:],\n",
    "            'word[:2]=' + word[:2],\n",
    "            'word[:3]=' + word[:3],\n",
    "            'word[:4]=' + word[:4],\n",
    "            'word[:5]=' + word[:5],\n",
    "            'word.length=%s' % len(word),\n",
    "            'word.isupper=%s' % word.isupper(),\n",
    "            'word.isupperandlower=%s' % bool(lower.match(word) and upper.match(word)),\n",
    "            'word.containdigit=%s' % bool(re.search(r'\\d', word)),\n",
    "            'word.containdash=%s' % ('-' in word),\n",
    "            'word.postag=' + pos_tag[i],\n",
    "            'word.postag_1=' + pos_tag[i][0],\n",
    "            'word.isalpha=%s' % word.isalpha(),\n",
    "            'word.istitle=%s' % word.istitle()\n",
    "        ]\n",
    "            \n",
    "        features.append(feature_vector)\n",
    "      \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a function that is able to read the feature vectors generated by the *extract_features* function and the ground truth of each vector. For that reason we define *read_features_and_classes(inputfile)* function.\n",
    "\n",
    "Basically it receives the path of the input file containing all the feature vectors. For a given sentence id it reads all its features and it appends it in a feature vector. Finally it returns all the features, a vector containing all feature_vectors (one for sentence), and the classes of each feature_vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_features_and_classes(inputfile):\n",
    "    features = []\n",
    "    classes = []\n",
    "    prev_sent_id = ''\n",
    "    with open(inputfile) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            saved_features = line.split()\n",
    "            sent_id = saved_features[0]\n",
    "            \n",
    "            if i == 0:\n",
    "                feature_vector = []\n",
    "                classes_vector = []\n",
    "                feature_vector.append(saved_features[5:])\n",
    "                classes_vector.append(saved_features[4])\n",
    "            \n",
    "            elif sent_id == prev_sent_id:\n",
    "                feature_vector.append(saved_features[5:])\n",
    "                classes_vector.append(saved_features[4])\n",
    "            \n",
    "            else:\n",
    "                features.append(feature_vector)\n",
    "                classes.append(classes_vector)\n",
    "                feature_vector = []\n",
    "                classes_vector = []\n",
    "            \n",
    "            prev_sent_id = sent_id\n",
    "    \n",
    "    return features, classes    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function defined above is called on the *train(features_file, model_name)* function, where we use the features and classes read in the features_file to train the CRF model and save it with the name model_name.\n",
    "\n",
    "To do so we use the CRF given by the pycrfsuite library. After tuning different parameters and doing a Grid Search we found that the best parameters were:\n",
    "- algorithm: 'pa'\n",
    "- 'c': 0.21600273890535607,\n",
    "- 'epsilon': 0.004802939229551229,\n",
    "- 'type': 2,\n",
    "- 'feature.possible_transitions': True,\n",
    "- 'feature.possible_states': True,\n",
    "- 'max_iterations': 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features_file, model_name):\n",
    "    # Get features of train data\n",
    "    features_train, gs_train = read_features_and_classes(features_file)\n",
    "\n",
    "    crf = pycrfsuite.Trainer(algorithm='pa', verbose=False)\n",
    "    \n",
    "    params = {\n",
    "        'c': 0.21600273890535607,\n",
    "        'epsilon': 0.004802939229551229,\n",
    "        'type': 2,\n",
    "        'feature.possible_transitions': True,\n",
    "        'feature.possible_states': True,\n",
    "        'max_iterations': 100\n",
    "    }\n",
    "    \n",
    "    crf.set_params(params)\n",
    "    \n",
    "    for xseq, yseq in zip(features_train, gs_train):\n",
    "        crf.append(xseq, yseq)\n",
    "\n",
    "    crf.train(model_name)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is the one used to predict the classes. It receives the tagger trained using the previous function and the features. It calls the classifier to get the classes B-I-O tags and the type of drug and it appends the result in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_classes(tagger, features):\n",
    "    classes = []\n",
    "    for ch in tagger.tag(features):\n",
    "        classes.append(ch)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have the *output_entities(sent_id, tokens, classes, outf)*. It receives a sentence id, its tokens, its classes (B-I-O tags with the type of drug) and a file where to write the output in order to evaluate the result.\n",
    "\n",
    "To output the entities in a proper output, we need to join the consequent words with tags starting by B-I. For that reason, this function, first, find all the words that have a tag starting with B, and if their following words have a tag starting with I, they are joined and written together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_entities(sent_id, tokens, classes, outf):\n",
    "    B_indices = [i for i in range(len(classes)) if classes[i].startswith('B')]\n",
    "    for b in B_indices:\n",
    "        I_indices = []\n",
    "        i = b + 1\n",
    "        while i < len(classes) and classes[i].startswith('I'):\n",
    "            I_indices.append(i)\n",
    "            i+=1\n",
    "        \n",
    "        if len(I_indices) == 0:\n",
    "            outf.write(sent_id+'|'+str(tokens[b][1])+'-'+str(tokens[b][2])+'|'+tokens[b][0]+'|'+classes[b][2:])\n",
    "        else:\n",
    "            joined_tokens = ' '.join([tokens[j][0] for j in [b] + I_indices])\n",
    "            outf.write(sent_id+'|'+str(tokens[b][1])+'-'+str(tokens[I_indices[-1]][2])+'|'+joined_tokens+'|'+classes[b][2:])\n",
    "        \n",
    "        outf.write(\"\\n\")   \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "#### Devel\n",
    "```\n",
    "SCORES FOR THE GROUP: develGoal3 RUN=1\n",
    "\n",
    "Strict matching (boundaries + type)\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1458\t101\t0\t212\t65\t1771\t0.9\t0.82\t0.86\n",
    "\n",
    "\n",
    "\n",
    "Exact matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1512\t47\t0\t212\t65\t1771\t0.93\t0.85\t0.89\n",
    "\n",
    "\n",
    "\n",
    "Partial matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1512\t0\t47\t212\t65\t1771\t0.93\t0.87\t0.9\n",
    "\n",
    "\n",
    "\n",
    "type matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1500\t59\t0\t212\t65\t1771\t0.92\t0.85\t0.88\n",
    "\n",
    "\n",
    "\n",
    "SCORES FOR ENTITY TYPE\n",
    "Exact matching on drug\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "925\t3\t0\t117\t39\t1045\t0.96\t0.89\t0.92\n",
    "\n",
    "\n",
    "Exact matching on brand\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "152\t0\t0\t28\t4\t180\t0.97\t0.84\t0.9\n",
    "\n",
    "\n",
    "Exact matching on group\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "354\t39\t0\t61\t22\t454\t0.85\t0.78\t0.81\n",
    "\n",
    "\n",
    "Exact matching on drug_n\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "27\t0\t0\t65\t1\t92\t0.96\t0.29\t0.45\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "P\tR\tF1\n",
    "0.94\t0.7\t0.77\n",
    "```\n",
    "\n",
    "#### Test\n",
    "```\n",
    "SCORES FOR THE GROUP: testGoal3 RUN=1\n",
    "\n",
    "Strict matching (boundaries + type)\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "463\t81\t0\t142\t48\t686\t0.78\t0.67\t0.72\n",
    "\n",
    "\n",
    "\n",
    "Exact matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "510\t34\t0\t142\t48\t686\t0.86\t0.74\t0.8\n",
    "\n",
    "\n",
    "\n",
    "Partial matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "510\t0\t34\t142\t48\t686\t0.86\t0.77\t0.81\n",
    "\n",
    "\n",
    "\n",
    "type matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "477\t67\t0\t142\t48\t686\t0.81\t0.7\t0.75\n",
    "\n",
    "\n",
    "\n",
    "SCORES FOR ENTITY TYPE\n",
    "Exact matching on drug\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "288\t6\t0\t57\t25\t351\t0.9\t0.82\t0.86\n",
    "\n",
    "\n",
    "Exact matching on brand\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "40\t0\t0\t19\t0\t59\t1\t0.68\t0.81\n",
    "\n",
    "\n",
    "Exact matching on group\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "126\t9\t0\t20\t11\t155\t0.86\t0.81\t0.84\n",
    "\n",
    "\n",
    "Exact matching on drug_n\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "9\t1\t0\t111\t1\t121\t0.82\t0.07\t0.14\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "P\tR\tF1\n",
    "0.9\t0.6\t0.66\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "The final results obtained are:\n",
    "\n",
    "**Devel: precision 0.94, recall 0.7, F1 0.77**\n",
    "\n",
    "**Test: precision 0.9, recall 0.6, F1 0.66**\n",
    "\n",
    "\n",
    "The results obtained with this approach show that for all of the drugs types the presicion value increases significantly while the recall is almost maintained. Therefore this means that the F1 value is higher for almost all of the types. Hence this approach that uses machine learning that makes use of the specified features, help to generalize much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal 4 : ML, using external knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In this last goal, we use also a CRF model but including also knowledge from external sources.\n",
    "\n",
    "With this system we want to achieve an overall F1 score of at least 0.7 on Devel dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the functions used to extract the knowledge from these external sources. We use two different functions:\n",
    "- *extract_drug_bank(drug_bank_path)*: this function is used to extract information of the DrugBank dataset. Is similar to the one used in Goal 2. We extract a dictionary with the drug names and their types. However, in this one we also extract a dictionary with all the words found in the drug names of the dictionary and their position inside its drug name. Our plan is to use this information to have a feature that is able to distinguish between B and I tags.\n",
    "- *extract_HSDB(HSDB_path)*: function that returns a list with all the drug names found in HSDB dataset. In a first approach we also extracted the position of each word inside its drug name, but the results were worse, so we discarded it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_drug_bank(drug_bank_path):\n",
    "    drug_bank = {}\n",
    "    positions_drug_bank = {}\n",
    "    with open(drug_bank_path, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            data = line.strip().split('|')\n",
    "            drug_name = data[0].lower()\n",
    "            drug_type = data[1]\n",
    "            drug_bank[drug_name] = drug_type\n",
    "            \n",
    "            for i in range(len(drug_name.split())):\n",
    "                positions_drug_bank[drug_name[i]] = i\n",
    "                \n",
    "    return drug_bank, positions_drug_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_HSDB(HSDB_path):\n",
    "    HSDB = []\n",
    "    with open(HSDB_path, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            data = line.strip()\n",
    "            HSDB.append(data.lower())\n",
    "    return HSDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use information from external resources and try to improve the performance we add the following features:\n",
    "- Boolean indicating the word is in DrugBank as a drug name itself.\n",
    "- Boolean indicating if the word is in HSDB as a drug name itself.\n",
    "- Boolean indicating if the word is a stopword.\n",
    "- The position of the word inside a drug name of the DrugBank, if it is there.\n",
    "- Type of drug of the word, if the word is in the DrugBank as a drug name.\n",
    "\n",
    "The rest of features is reused from the previous goal. However, we add some that were discarded before and in combination of the previous features perform better:\n",
    "- Booleans indicating if contains special characters and if it starts with a digit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tokens, pos_tag):\n",
    "    features = []\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        token = tokens[i]\n",
    "        word = token[0]\n",
    "        \n",
    "        lower = re.compile(r'.*[a-z]+')\n",
    "        upper = re.compile(r'.*[A-Z]+')\n",
    "        \n",
    "        feature_vector = [\n",
    "            'word.lower=' + word.lower(),\n",
    "            'word[-5:]=' + word[-5:],\n",
    "            'word[-4:]=' + word[-4:],\n",
    "            'word[-3:]=' + word[-3:],\n",
    "            'word[-2:]=' + word[-2:],\n",
    "            'word[:2]=' + word[:2],\n",
    "            'word[:3]=' + word[:3],\n",
    "            'word[:4]=' + word[:4],\n",
    "            'word[:5]=' + word[:5],\n",
    "            'word.length=%s' % len(word),\n",
    "            'word.isupper=%s' % word.isupper(),\n",
    "            'word.isupperandlower=%s' % bool(lower.match(word) and upper.match(word)),\n",
    "            'word.containdigit=%s' % bool(re.search(r'\\d', word)),\n",
    "            'word.containdash=%s' % ('-' in word),\n",
    "            'word.postag=' + pos_tag[i],\n",
    "            'word.postag_1=' + pos_tag[i][0],\n",
    "            'word.isalpha=%s' % word.isalpha(),\n",
    "            'word.istitle=%s' % word.istitle(),\n",
    "            'word.startswithdigit=%s' % word[0].isdigit(),\n",
    "            'word.inbank=%s' % (word.lower() in drug_bank.keys()),\n",
    "            'word.inHSDB=%s' % (word.lower() in HSDB),\n",
    "            'word.stopword=%s' % (word.lower() in stopwords),\n",
    "        ]\n",
    "        \n",
    "        if word.lower() in positions_drug_bank.keys():\n",
    "                feature_vector.append('word.position_inbank=%s' %(positions_drug_bank[word.lower()]))\n",
    "        \n",
    "        if word.lower() in drug_bank.keys():\n",
    "                feature_vector.append('word.type_inbank=' + drug_bank[word.lower()])\n",
    "        \n",
    "            \n",
    "        features.append(feature_vector)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last function changed from Goal 3 is *train*, where we changed the parameters by the default ones. After testing several parameters we found that the best ones were the default (except the algorithm, which is the same as in Goal 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features_file, model_name):\n",
    "    # Get features of train data\n",
    "    features_train, gs_train = read_features_and_classes(features_file)\n",
    "    \n",
    "    crf = pycrfsuite.Trainer(algorithm='pa', verbose=False)\n",
    "\n",
    "    for xseq, yseq in zip(features_train, gs_train):\n",
    "        crf.append(xseq, yseq)\n",
    "\n",
    "    crf.train(model_name)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "#### Devel\n",
    "```\n",
    "SCORES FOR THE GROUP: develGoal4 RUN=1\n",
    "\n",
    "Strict matching (boundaries + type)\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1511\t74\t0\t186\t56\t1771\t0.92\t0.85\t0.89\n",
    "\n",
    "\n",
    "\n",
    "Exact matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1538\t47\t0\t186\t56\t1771\t0.94\t0.87\t0.9\n",
    "\n",
    "\n",
    "\n",
    "Partial matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1538\t0\t47\t186\t56\t1771\t0.94\t0.88\t0.91\n",
    "\n",
    "\n",
    "\n",
    "type matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1552\t33\t0\t186\t56\t1771\t0.95\t0.88\t0.91\n",
    "\n",
    "\n",
    "\n",
    "SCORES FOR ENTITY TYPE\n",
    "Exact matching on drug\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "963\t4\t0\t78\t20\t1045\t0.98\t0.92\t0.95\n",
    "\n",
    "\n",
    "Exact matching on brand\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "171\t0\t0\t9\t1\t180\t0.99\t0.95\t0.97\n",
    "\n",
    "\n",
    "Exact matching on group\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "351\t37\t0\t66\t21\t454\t0.86\t0.77\t0.81\n",
    "\n",
    "\n",
    "Exact matching on drug_n\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "26\t0\t0\t66\t1\t92\t0.96\t0.28\t0.44\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "P\tR\tF1\n",
    "0.95\t0.73\t0.79\n",
    "```\n",
    "\n",
    "#### Test\n",
    "```\n",
    "SCORES FOR THE GROUP: testGoal4 RUN=1\n",
    "\n",
    "Strict matching (boundaries + type)\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "485\t84\t0\t117\t38\t686\t0.8\t0.71\t0.75\n",
    "\n",
    "\n",
    "\n",
    "Exact matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "543\t26\t0\t117\t38\t686\t0.89\t0.79\t0.84\n",
    "\n",
    "\n",
    "\n",
    "Partial matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "543\t0\t26\t117\t38\t686\t0.89\t0.81\t0.85\n",
    "\n",
    "\n",
    "\n",
    "type matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "500\t69\t0\t117\t38\t686\t0.82\t0.73\t0.77\n",
    "\n",
    "\n",
    "\n",
    "SCORES FOR ENTITY TYPE\n",
    "Exact matching on drug\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "308\t6\t0\t37\t27\t351\t0.9\t0.88\t0.89\n",
    "\n",
    "\n",
    "Exact matching on brand\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "48\t0\t0\t11\t0\t59\t1\t0.81\t0.9\n",
    "\n",
    "\n",
    "Exact matching on group\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "118\t10\t0\t27\t11\t155\t0.85\t0.76\t0.8\n",
    "\n",
    "\n",
    "Exact matching on drug_n\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "11\t1\t0\t109\t1\t121\t0.85\t0.09\t0.16\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "P\tR\tF1\n",
    "0.9\t0.64\t0.69\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The final results obtained are:\n",
    "\n",
    "**Devel: precision 0.95, recall 0.73, F1 0.79**\n",
    "\n",
    "**Test: precision 0.9, recall 0.64, F1 0.69**\n",
    "\n",
    "The result obtained by applying external resources to the previous model helps to be more accurate and improve and raise the results previusly obained.\n",
    "\n",
    "However, the improvement has been very small, specially for the Devel dataset. We think this is because the result obtained in the previous goal was already very good so the room for improvement was small."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
