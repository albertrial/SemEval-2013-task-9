{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AHLT - First delivery - Task 9.1 NERC\n",
    "**Albert Rial**   \n",
    "**Karen Lliguin**   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This delivery consists of solving the task 9.1 of the SemEval-2013 challenge. The task concerns the named entity recognition and classification of drug names.  \n",
    "\n",
    "The dataset provided contains XML files with sentences and the entities appearing on it and their corresponding type. There are four general types: drug, brand, group and drug_n. The data is already splitted in three subsets: Train, Devel and Test.\n",
    "\n",
    "We are also provided with some external resources containing knowledge extracted from other databases (DrugBank, HSDB) and with evaluation scripts.\n",
    "\n",
    "To do so, we use different methods and resources and we divide the task in different subtasks/goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal 1: Rule-based, no external knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "First, we develop a simple rule-based baseline system to carry out the task. In this first version we only use the information from the Train dataset and we do not use external knowledge. \n",
    "\n",
    "With this we want to achieve an overall F1 score of at least 0.5 on the Devel dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration\n",
    "To do this system, first we do a data exploration to know which common characteristics have the drugs in each type.\n",
    "\n",
    "Given only the Train dataset, we analyze the following aspects:\n",
    "- The most common words that appear after and before each type of drug.\n",
    "- The most common prefixes and sufixes of each type of drug (given different number of characters).\n",
    "- The most common drug entities of each type.\n",
    "    \n",
    "You can find the full code of the data exploration in the jupyter notebook called *data_exploration.ipynb*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details\n",
    "The main function of our system is *extract_entities(tokens)*, where, given a list with the tokens of a sentence and taking into account the rules defined, we return a list of the entities we found and their type.\n",
    "\n",
    "Basically we loop over all the tokens and using the following rules we try to recognize and classify the drugs appearing. The rules are:\n",
    "- Sufixes and prefixes: we use the most common prefixes and sufixes found on the data exploration for each type of drug. If we find a word with an specific prefix or sufix that is in our list of common prefixes and sufixes of a type, we consider the word as an entity and we classify it in the corresponding type.\n",
    "- For the types drug_n and brand we also check if the word is uppercase. If is uppercase and the length is greater than 4, we classify the word as brand. Otherwise, if the word is uppercase and the length is less or equal than 4, we classify it as drug_n.\n",
    "- As in data exploration we observed that type group contained several drug names formed by two words, we add a rule taking care of checking whether two consequent words are classified as drug, in order to distinguish this type of drug names. \n",
    "- As drug_n still showed a low F1 score, a rule checking whether the word contain the character \"-\" or digits is added, as from the previous analysis this pattern was observed in the names of the drugs of that partucular type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(tokens):\n",
    "    entities = [] # Output list of entities\n",
    "    prev_drug = \"\" # Previous drug found (if any)\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        token = tokens[i]\n",
    "        word = token[0]\n",
    "        \n",
    "        # Prefix and sufix rules\n",
    "        drug_prefixes = ('pheny', 'digox', 'warfa', 'meth', 'theophy', 'lith', 'keto', 'cime', 'insu', 'fluox', 'alcoh', 'cyclos', 'eryth', 'carba', 'rifa', 'caffe')\n",
    "        drug_sufixes = ('pitant', 'dine', 'azole', 'mide', 'pine', 'line', 'mine', 'tine', 'arin', 'avir', 'azem', 'rine', 'rone', 'arbital', 'olol', 'afil', 'inol', 'zolam')\n",
    "        \n",
    "        group_prefixes = ('benzo', 'beta', 'antico', 'antide', 'antibi', 'antihi', 'nsai', 'contra')\n",
    "        group_sufixes = ('steroids','tics', 'ants', 'ents', 'tors', 'acid', 'acids', 'ceptives', 'gens', 'pines', 'lines', 'mines')\n",
    "        \n",
    "        brand_prefixes = ('aspi', 'accu', 'beza', 'star', 'exja')\n",
    "        brand_sufixes = ('tane', 'dine', 'anil')\n",
    "        \n",
    "        drug_n_prefixes = ('ibog', 'endo')\n",
    "        drug_n_sufixes = ('ate', 'sin', 'toxin', 'orfon')\n",
    "        \n",
    "        # Rules for drug type\n",
    "        if word.lower().startswith(drug_prefixes) or word.lower().endswith(drug_sufixes):\n",
    "            entities.append({'name':word, 'offset': str(token[1])+'-'+str(token[2]),'type':'drug'})\n",
    "            prev_drug = str(word)+ \" \"+str(token[1])+\" \"+\"drug\"\n",
    "        \n",
    "        # Rules for group type\n",
    "        elif word.lower().startswith(group_prefixes) or word.lower().endswith(group_sufixes):\n",
    "            if prev_drug != '':\n",
    "                info = prev_drug.split(\" \")\n",
    "                if len(entities) > 0 and info[2]=='group':\n",
    "                    entities.pop()\n",
    "                    entities.append({'name':str(info[0])+word, 'offset': str(info[1])+'-'+str(token[2]),'type':'group'})\n",
    "            else:\n",
    "                entities.append({'name':word, 'offset': str(token[1])+'-'+str(token[2]),'type':'group'})\n",
    "            prev_drug = str(word)+ \" \"+str(token[1])+ \" \"+\"group\"\n",
    "        \n",
    "        # Rules for brand type\n",
    "        elif (word.isupper() and len(word)>4) or word.lower().startswith(brand_prefixes) or word.lower().endswith(brand_sufixes):\n",
    "            entities.append({'name':word, 'offset': str(token[1])+'-'+str(token[2]),'type':'brand'})\n",
    "            prev_drug = str(word)+ \" \"+str(token[1])+ \" \"+ \"brand\"\n",
    "        \n",
    "        # Rules for drug_n type\n",
    "        elif word.isupper() or word.lower().startswith(drug_n_prefixes) or word.lower().endswith(drug_n_prefixes)\\\n",
    "        or (bool(re.search(r'\\d', word)) and '-' in word):\n",
    "            entities.append({'name':word, 'offset': str(token[1])+'-'+str(token[2]),'type':'drug_n'})\n",
    "            prev_drug = str(word)+ \" \"+str(token[1])+ \" \"+\"drug_n\"\n",
    "            \n",
    "        else:\n",
    "            prev_drug = \"\"\n",
    "        \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "#### Devel\n",
    "\n",
    "(The results of the analysis are contaied in the notebook _data_exploration_ on the Apendix folder)\n",
    "\n",
    "```\n",
    "The evaluator output for this version on devel is shown below\n",
    "\n",
    "SCORES FOR THE GROUP: develGoal1 RUN=1\n",
    "\n",
    "Strict matching (boundaries + type)\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "773\t292\t0\t706\t496\t1771\t0.5\t0.44\t0.46\n",
    "\n",
    "\n",
    "\n",
    "Exact matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "815\t250\t0\t706\t496\t1771\t0.52\t0.46\t0.49\n",
    "\n",
    "\n",
    "\n",
    "Partial matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "815\t0\t250\t706\t496\t1771\t0.52\t0.53\t0.53\n",
    "\n",
    "\n",
    "\n",
    "type matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "904\t161\t0\t706\t496\t1771\t0.58\t0.51\t0.54\n",
    "\n",
    "\n",
    "\n",
    "SCORES FOR ENTITY TYPE\n",
    "Exact matching on drug\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "511\t14\t0\t520\t45\t1045\t0.9\t0.49\t0.63\n",
    "\n",
    "\n",
    "Exact matching on brand\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "115\t0\t0\t65\t25\t180\t0.82\t0.64\t0.72\n",
    "\n",
    "\n",
    "Exact matching on group\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "120\t117\t0\t217\t83\t454\t0.38\t0.26\t0.31\n",
    "\n",
    "\n",
    "Exact matching on drug_n\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "27\t0\t0\t65\t33\t92\t0.45\t0.29\t0.36\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "P\tR\tF1\n",
    "0.64\t0.42\t0.5\n",
    "```\n",
    "\n",
    "#### Test\n",
    "\n",
    "The evaluator output for this version on test is shown below\n",
    "\n",
    "```\n",
    "SCORES FOR THE GROUP: testGoal1 RUN=1\n",
    "\n",
    "Strict matching (boundaries + type)\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "214\t109\t0\t363\t331\t686\t0.33\t0.31\t0.32\n",
    "\n",
    "\n",
    "\n",
    "Exact matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "242\t81\t0\t363\t331\t686\t0.37\t0.35\t0.36\n",
    "\n",
    "\n",
    "\n",
    "Partial matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "242\t0\t81\t363\t331\t686\t0.37\t0.41\t0.39\n",
    "\n",
    "\n",
    "\n",
    "type matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "252\t71\t0\t363\t331\t686\t0.39\t0.37\t0.38\n",
    "\n",
    "\n",
    "\n",
    "SCORES FOR ENTITY TYPE\n",
    "Exact matching on drug\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "124\t8\t0\t219\t31\t351\t0.76\t0.35\t0.48\n",
    "\n",
    "\n",
    "Exact matching on brand\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "26\t0\t0\t33\t1\t59\t0.96\t0.44\t0.6\n",
    "\n",
    "\n",
    "Exact matching on group\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "49\t16\t0\t90\t48\t155\t0.43\t0.32\t0.37\n",
    "\n",
    "\n",
    "Exact matching on drug_n\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "15\t15\t0\t91\t34\t121\t0.23\t0.12\t0.16\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "P\tR\tF1\n",
    "0.6\t0.31\t0.4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal 2 : Rule-based, using external knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Once accomplished the first goal we use the rule-based system defined but also using information from external knowledge sources.\n",
    "\n",
    "The goal is to obtain a F1 score of at least 0.6 on the Devel dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details\n",
    "The most part of the code is reused from the first approach. The only modifications done are:\n",
    "- extract_drug_bank(drug_bank_path): function where we read the DrugBank dataset and we store in a dictionary the drug name and the drug type given by the external dataset.\n",
    "- extract_entities(tokens): for each word we do:\n",
    "    - First, we check if the word is inside the DrugBank dataset. If it exists there, we classify it according to the type specified by the DrugBank.\n",
    "    - If it is not present, we check the drug_n rules that we had in our first approach. We do this because there is not any drug_n inside the DrugBank and is the class with worst F1 score.\n",
    "    - Finally, as a lot of drug names inside the DrugBank have more than one word, we check if the union of the word and its previous words appear in the DrugBank. In case they appear there, we add all the words as a single entity and with the corresponding type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_drug_bank(drug_bank_path):\n",
    "    drug_bank = {}\n",
    "    with open(drug_bank_path, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            data = line.strip().split('|')\n",
    "            drug_name = data[0]\n",
    "            drug_type = data[1]\n",
    "            drug_bank[drug_name.lower()] = drug_type\n",
    "    return drug_bank\n",
    "\n",
    "drug_bank = extract_drug_bank(drug_bank_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(tokens):\n",
    "    entities = []\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        token = tokens[i]\n",
    "        word = token[0]\n",
    "        \n",
    "        drug_n_prefixes = ('18-m', 'ibog', 'endo', 'toxi')\n",
    "        drug_n_sufixes = ('ine', 'ate', '8-mc', 'sin', 'xin', 'pge2', 'mhd')\n",
    "        \n",
    "        # Check if single word is in bank\n",
    "        if word.lower() in drug_bank:\n",
    "            entities.append({'name':word, 'offset': str(token[1])+'-'+str(token[2]),'type':drug_bank[word.lower()]})\n",
    "        \n",
    "        # Check drug_n rules\n",
    "        elif word.isupper() or word.lower().startswith(drug_n_prefixes) or word.lower().endswith(drug_n_prefixes):\n",
    "            entities.append({'name':word, 'offset': str(token[1])+'-'+str(token[2]),'type':'drug_n'})\n",
    "        \n",
    "        # Check if multiple consecutive words appear in the drug bank as a single drug\n",
    "        else:\n",
    "            for j in range(1, 5):\n",
    "                if i>=j-1:\n",
    "                    words_joined  = ' '.join([t[0] for t in tokens[i-j:i+1]])   \n",
    "                    if words_joined.lower() in drug_bank:\n",
    "                        entities.append({'name':words_joined, 'offset': str(tokens[i-j][1])+'-'+str(tokens[i][2]),'type':drug_bank[words_joined.lower()]})\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "#### Devel\n",
    "```\n",
    "SCORES FOR THE GROUP: develGoal2 RUN=1\n",
    "\n",
    "Strict matching (boundaries + type)\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1177\t350\t0\t244\t524\t1771\t0.57\t0.66\t0.62\n",
    "\n",
    "\n",
    "\n",
    "Exact matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1270\t257\t0\t244\t524\t1771\t0.62\t0.72\t0.66\n",
    "\n",
    "\n",
    "\n",
    "Partial matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1270\t0\t257\t244\t524\t1771\t0.62\t0.79\t0.69\n",
    "\n",
    "\n",
    "\n",
    "type matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1291\t236\t0\t244\t524\t1771\t0.63\t0.73\t0.68\n",
    "\n",
    "\n",
    "\n",
    "SCORES FOR ENTITY TYPE\n",
    "Exact matching on drug\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "866\t44\t0\t135\t76\t1045\t0.88\t0.83\t0.85\n",
    "\n",
    "\n",
    "Exact matching on brand\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "170\t3\t0\t7\t32\t180\t0.83\t0.94\t0.88\n",
    "\n",
    "\n",
    "Exact matching on group\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "115\t52\t0\t287\t52\t454\t0.53\t0.25\t0.34\n",
    "\n",
    "\n",
    "Exact matching on drug_n\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "26\t15\t0\t51\t37\t92\t0.33\t0.28\t0.31\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "P\tR\tF1\n",
    "0.64\t0.58\t0.6\n",
    "```\n",
    "\n",
    "### Test\n",
    "```\n",
    "SCORES FOR THE GROUP: testGoal2 RUN=1\n",
    "\n",
    "Strict matching (boundaries + type)\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "401\t160\t0\t125\t334\t686\t0.45\t0.58\t0.51\n",
    "\n",
    "\n",
    "\n",
    "Exact matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "482\t79\t0\t125\t334\t686\t0.54\t0.7\t0.61\n",
    "\n",
    "\n",
    "\n",
    "Partial matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "482\t0\t79\t125\t334\t686\t0.54\t0.76\t0.63\n",
    "\n",
    "\n",
    "\n",
    "type matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "439\t122\t0\t125\t334\t686\t0.49\t0.64\t0.56\n",
    "\n",
    "\n",
    "\n",
    "SCORES FOR ENTITY TYPE\n",
    "Exact matching on drug\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "299\t18\t0\t34\t62\t351\t0.79\t0.85\t0.82\n",
    "\n",
    "\n",
    "Exact matching on brand\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "50\t4\t0\t5\t8\t59\t0.81\t0.85\t0.83\n",
    "\n",
    "\n",
    "Exact matching on group\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "41\t10\t0\t104\t21\t155\t0.57\t0.26\t0.36\n",
    "\n",
    "\n",
    "Exact matching on drug_n\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "11\t6\t0\t104\t31\t121\t0.23\t0.09\t0.13\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "P\tR\tF1\n",
    "0.6\t0.51\t0.53\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal 3 : ML, no external knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying a rule-based system and viewing its limitations, in this goal we try to solve the same problem (NERC) using machine learning techniques.\n",
    "\n",
    "Specifically we use a CRF model to solve the task. We do the following steps:\n",
    "- Extract and define different features to encode the data.\n",
    "- Train and tune a model with the obtained feature vectors of the Train dataset.\n",
    "- Test the model using Devel and Test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration\n",
    "To do this system, we reused the data exploration done on the first goal and we defined most of the features based on that. In the next section we will detail all the features used (the ones finally used and the ones tested but discarded)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details\n",
    "In the following function *extract_features(tokens, pos_tag)* we receive the tokens of a sentence and their POS tag, and we extract different features to encode the data.\n",
    "\n",
    "The features defined are:\n",
    "- Word in lowercase\n",
    "- Prefixes and sufixes (from 2 characters to 5)\n",
    "- Word length\n",
    "- POS tag of the word\n",
    "- First character of the POS tag\n",
    "- Booleans indicating if the word is uppercase, if contains uppercase and lowercase characters, if contains digits, if contains dash, if is only composed by letters and if is title.\n",
    "\n",
    "Other features have been tested but it have been discarded because they were not improving the performance. Some of them are:\n",
    "- Booleans indicating if the word is a punctuation, if contains special characters and if it starts with a digit.\n",
    "- Similar features as the ones above but with information about the previous and next word (previous and next word in lowercase, length of both, their POS tag, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tokens, pos_tag):\n",
    "    features = []\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        token = tokens[i]\n",
    "        word = token[0]\n",
    "        \n",
    "        lower = re.compile(r'.*[a-z]+')\n",
    "        upper = re.compile(r'.*[A-Z]+')\n",
    "        \n",
    "        feature_vector = [\n",
    "            'word.lower=' + word.lower(),\n",
    "            'word[-5:]=' + word[-5:],\n",
    "            'word[-4:]=' + word[-4:],\n",
    "            'word[-3:]=' + word[-3:],\n",
    "            'word[-2:]=' + word[-2:],\n",
    "            'word[:2]=' + word[:2],\n",
    "            'word[:3]=' + word[:3],\n",
    "            'word[:4]=' + word[:4],\n",
    "            'word[:5]=' + word[:5],\n",
    "            'word.length=%s' % len(word),\n",
    "            'word.isupper=%s' % word.isupper(),\n",
    "            'word.isupperandlower=%s' % bool(lower.match(word) and upper.match(word)),\n",
    "            'word.containdigit=%s' % bool(re.search(r'\\d', word)),\n",
    "            'word.containdash=%s' % ('-' in word),\n",
    "            'word.postag=' + pos_tag[i],\n",
    "            'word.postag_1=' + pos_tag[i][0],\n",
    "            'word.isalpha=%s' % word.isalpha(),\n",
    "            'word.istitle=%s' % word.istitle()\n",
    "        ]\n",
    "            \n",
    "        features.append(feature_vector)\n",
    "      \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a function that is able to read the feature vectors generated by the *extract_features* function and the ground truth of each vector. For that reason we define *read_features_and_classes(inputfile)* function.\n",
    "\n",
    "Basically it receives the path of the input file containing all the feature vectors. For a given sentence id it reads all its features and it appends it in a feature vector. Finally it returns all the features, a vector containing all feature_vectors (one for sentence), and the classes of each feature_vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_features_and_classes(inputfile):\n",
    "    features = []\n",
    "    classes = []\n",
    "    prev_sent_id = ''\n",
    "    with open(inputfile) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            saved_features = line.split()\n",
    "            sent_id = saved_features[0]\n",
    "            \n",
    "            if i == 0:\n",
    "                feature_vector = []\n",
    "                classes_vector = []\n",
    "                feature_vector.append(saved_features[5:])\n",
    "                classes_vector.append(saved_features[4])\n",
    "            \n",
    "            elif sent_id == prev_sent_id:\n",
    "                feature_vector.append(saved_features[5:])\n",
    "                classes_vector.append(saved_features[4])\n",
    "            \n",
    "            else:\n",
    "                features.append(feature_vector)\n",
    "                classes.append(classes_vector)\n",
    "                feature_vector = []\n",
    "                classes_vector = []\n",
    "            \n",
    "            prev_sent_id = sent_id\n",
    "    \n",
    "    return features, classes    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features_file, model_name):\n",
    "    # Get features of train data\n",
    "    features_train, gs_train = read_features_and_classes(features_file)\n",
    "\n",
    "    crf = pycrfsuite.Trainer(algorithm='pa', verbose=False)\n",
    "    \n",
    "    params = {\n",
    "        'c': 0.21600273890535607,\n",
    "        'epsilon': 0.004802939229551229,\n",
    "        'type': 2,\n",
    "        'feature.possible_transitions': True,\n",
    "        'feature.possible_states': True,\n",
    "        'max_iterations': 100\n",
    "    }\n",
    "    \n",
    "    crf.set_params(params)\n",
    "    \n",
    "    for xseq, yseq in zip(features_train, gs_train):\n",
    "        crf.append(xseq, yseq)\n",
    "\n",
    "    crf.train(model_name)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_features(sent_id, inputfile):\n",
    "    features = []\n",
    "    with open(inputfile) as f:\n",
    "        features = [line.split()[5:] for line in f if line.split()[0] == sent_id]\n",
    "        \n",
    "    return features    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_classes(tagger, features):\n",
    "    classes = []\n",
    "    for ch in tagger.tag(features):\n",
    "        classes.append(ch)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_entities(sent_id, tokens, classes, outf):\n",
    "    B_indices = [i for i in range(len(classes)) if classes[i].startswith('B')]\n",
    "    for b in B_indices:\n",
    "        I_indices = []\n",
    "        i = b + 1\n",
    "        while i < len(classes) and classes[i].startswith('I'):\n",
    "            I_indices.append(i)\n",
    "            i+=1\n",
    "        \n",
    "        if len(I_indices) == 0:\n",
    "            outf.write(sent_id+'|'+str(tokens[b][1])+'-'+str(tokens[b][2])+'|'+tokens[b][0]+'|'+classes[b][2:])\n",
    "        else:\n",
    "            joined_tokens = ' '.join([tokens[j][0] for j in [b] + I_indices])\n",
    "            outf.write(sent_id+'|'+str(tokens[b][1])+'-'+str(tokens[I_indices[-1]][2])+'|'+joined_tokens+'|'+classes[b][2:])\n",
    "        \n",
    "        outf.write(\"\\n\")   \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "#### Devel\n",
    "```\n",
    "SCORES FOR THE GROUP: develGoal3 RUN=1\n",
    "\n",
    "Strict matching (boundaries + type)\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1458\t101\t0\t212\t65\t1771\t0.9\t0.82\t0.86\n",
    "\n",
    "\n",
    "\n",
    "Exact matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1512\t47\t0\t212\t65\t1771\t0.93\t0.85\t0.89\n",
    "\n",
    "\n",
    "\n",
    "Partial matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1512\t0\t47\t212\t65\t1771\t0.93\t0.87\t0.9\n",
    "\n",
    "\n",
    "\n",
    "type matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1500\t59\t0\t212\t65\t1771\t0.92\t0.85\t0.88\n",
    "\n",
    "\n",
    "\n",
    "SCORES FOR ENTITY TYPE\n",
    "Exact matching on drug\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "925\t3\t0\t117\t39\t1045\t0.96\t0.89\t0.92\n",
    "\n",
    "\n",
    "Exact matching on brand\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "152\t0\t0\t28\t4\t180\t0.97\t0.84\t0.9\n",
    "\n",
    "\n",
    "Exact matching on group\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "354\t39\t0\t61\t22\t454\t0.85\t0.78\t0.81\n",
    "\n",
    "\n",
    "Exact matching on drug_n\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "27\t0\t0\t65\t1\t92\t0.96\t0.29\t0.45\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "P\tR\tF1\n",
    "0.94\t0.7\t0.77\n",
    "```\n",
    "\n",
    "#### Test\n",
    "```\n",
    "SCORES FOR THE GROUP: testGoal3 RUN=1\n",
    "\n",
    "Strict matching (boundaries + type)\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "463\t81\t0\t142\t48\t686\t0.78\t0.67\t0.72\n",
    "\n",
    "\n",
    "\n",
    "Exact matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "510\t34\t0\t142\t48\t686\t0.86\t0.74\t0.8\n",
    "\n",
    "\n",
    "\n",
    "Partial matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "510\t0\t34\t142\t48\t686\t0.86\t0.77\t0.81\n",
    "\n",
    "\n",
    "\n",
    "type matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "477\t67\t0\t142\t48\t686\t0.81\t0.7\t0.75\n",
    "\n",
    "\n",
    "\n",
    "SCORES FOR ENTITY TYPE\n",
    "Exact matching on drug\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "288\t6\t0\t57\t25\t351\t0.9\t0.82\t0.86\n",
    "\n",
    "\n",
    "Exact matching on brand\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "40\t0\t0\t19\t0\t59\t1\t0.68\t0.81\n",
    "\n",
    "\n",
    "Exact matching on group\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "126\t9\t0\t20\t11\t155\t0.86\t0.81\t0.84\n",
    "\n",
    "\n",
    "Exact matching on drug_n\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "9\t1\t0\t111\t1\t121\t0.82\t0.07\t0.14\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "P\tR\tF1\n",
    "0.9\t0.6\t0.66\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal 4 : ML, using external knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_drug_bank(drug_bank_path):\n",
    "    drug_bank = {}\n",
    "    positions_drug_bank = {}\n",
    "    with open(drug_bank_path, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            data = line.strip().split('|')\n",
    "            drug_name = data[0].lower()\n",
    "            drug_type = data[1]\n",
    "            drug_bank[drug_name] = drug_type\n",
    "            \n",
    "            for i in range(len(drug_name.split())):\n",
    "                positions_drug_bank[drug_name[i]] = i\n",
    "                \n",
    "    return drug_bank, positions_drug_bank\n",
    "\n",
    "drug_bank, positions_drug_bank = extract_drug_bank(drug_bank_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_HSDB(HSDB_path):\n",
    "    HSDB = []\n",
    "    with open(HSDB_path, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            data = line.strip()\n",
    "            HSDB.append(data.lower())\n",
    "    return HSDB\n",
    "\n",
    "HSDB = extract_HSDB(HSDB_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tokens, pos_tag):\n",
    "    features = []\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        token = tokens[i]\n",
    "        word = token[0]\n",
    "        \n",
    "        lower = re.compile(r'.*[a-z]+')\n",
    "        upper = re.compile(r'.*[A-Z]+')\n",
    "        \n",
    "        feature_vector = [\n",
    "            'word.lower=' + word.lower(),\n",
    "            'word[-5:]=' + word[-5:],\n",
    "            'word[-4:]=' + word[-4:],\n",
    "            'word[-3:]=' + word[-3:],\n",
    "            'word[-2:]=' + word[-2:],\n",
    "            'word[:2]=' + word[:2],\n",
    "            'word[:3]=' + word[:3],\n",
    "            'word[:4]=' + word[:4],\n",
    "            'word[:5]=' + word[:5],\n",
    "            'word.length=%s' % len(word),\n",
    "            'word.isupper=%s' % word.isupper(),\n",
    "            'word.isupperandlower=%s' % bool(lower.match(word) and upper.match(word)),\n",
    "            'word.containdigit=%s' % bool(re.search(r'\\d', word)),\n",
    "            'word.containdash=%s' % ('-' in word),\n",
    "            'word.postag=' + pos_tag[i],\n",
    "            'word.postag_1=' + pos_tag[i][0],\n",
    "            'word.specialchar=%s' % bool(re.search('^[a-zA-Z0-9]*$',word)),\n",
    "            'word.isalpha=%s' % word.isalpha(),\n",
    "            'word.istitle=%s' % word.istitle(),\n",
    "            'word.startswithdigit=%s' % word[0].isdigit(),\n",
    "            'word.inbank=%s' % (word.lower() in drug_bank.keys()),\n",
    "            'word.inHSDB=%s' % (word.lower() in HSDB),\n",
    "            'word.stopword=%s' % (word.lower() in stopwords),\n",
    "        ]\n",
    "        \n",
    "        if word.lower() in positions_drug_bank.keys():\n",
    "                feature_vector.append('word.position_inbank=%s' %(positions_drug_bank[word.lower()]))\n",
    "        \n",
    "        if word.lower() in drug_bank.keys():\n",
    "                feature_vector.append('word.type_inbank=' + drug_bank[word.lower()])\n",
    "        \n",
    "            \n",
    "        features.append(feature_vector)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features_file, model_name):\n",
    "    # Get features of train data\n",
    "    features_train, gs_train = read_features_and_classes(features_file)\n",
    "    \n",
    "    crf = pycrfsuite.Trainer(algorithm='pa', verbose=False)\n",
    "\n",
    "    for xseq, yseq in zip(features_train, gs_train):\n",
    "        crf.append(xseq, yseq)\n",
    "\n",
    "    crf.train(model_name)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "#### Devel\n",
    "```\n",
    "SCORES FOR THE GROUP: develGoal4 RUN=1\n",
    "\n",
    "Strict matching (boundaries + type)\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1511\t74\t0\t186\t56\t1771\t0.92\t0.85\t0.89\n",
    "\n",
    "\n",
    "\n",
    "Exact matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1538\t47\t0\t186\t56\t1771\t0.94\t0.87\t0.9\n",
    "\n",
    "\n",
    "\n",
    "Partial matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1538\t0\t47\t186\t56\t1771\t0.94\t0.88\t0.91\n",
    "\n",
    "\n",
    "\n",
    "type matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "1552\t33\t0\t186\t56\t1771\t0.95\t0.88\t0.91\n",
    "\n",
    "\n",
    "\n",
    "SCORES FOR ENTITY TYPE\n",
    "Exact matching on drug\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "963\t4\t0\t78\t20\t1045\t0.98\t0.92\t0.95\n",
    "\n",
    "\n",
    "Exact matching on brand\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "171\t0\t0\t9\t1\t180\t0.99\t0.95\t0.97\n",
    "\n",
    "\n",
    "Exact matching on group\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "351\t37\t0\t66\t21\t454\t0.86\t0.77\t0.81\n",
    "\n",
    "\n",
    "Exact matching on drug_n\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "26\t0\t0\t66\t1\t92\t0.96\t0.28\t0.44\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "P\tR\tF1\n",
    "0.95\t0.73\t0.79\n",
    "```\n",
    "\n",
    "#### Test\n",
    "```\n",
    "SCORES FOR THE GROUP: testGoal4 RUN=1\n",
    "\n",
    "Strict matching (boundaries + type)\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "485\t84\t0\t117\t38\t686\t0.8\t0.71\t0.75\n",
    "\n",
    "\n",
    "\n",
    "Exact matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "543\t26\t0\t117\t38\t686\t0.89\t0.79\t0.84\n",
    "\n",
    "\n",
    "\n",
    "Partial matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "543\t0\t26\t117\t38\t686\t0.89\t0.81\t0.85\n",
    "\n",
    "\n",
    "\n",
    "type matching\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "500\t69\t0\t117\t38\t686\t0.82\t0.73\t0.77\n",
    "\n",
    "\n",
    "\n",
    "SCORES FOR ENTITY TYPE\n",
    "Exact matching on drug\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "308\t6\t0\t37\t27\t351\t0.9\t0.88\t0.89\n",
    "\n",
    "\n",
    "Exact matching on brand\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "48\t0\t0\t11\t0\t59\t1\t0.81\t0.9\n",
    "\n",
    "\n",
    "Exact matching on group\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "118\t10\t0\t27\t11\t155\t0.85\t0.76\t0.8\n",
    "\n",
    "\n",
    "Exact matching on drug_n\n",
    "cor\tinc\tpar\tmis\tspu\ttotal\tprec\trecall\tF1\n",
    "11\t1\t0\t109\t1\t121\t0.85\t0.09\t0.16\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "P\tR\tF1\n",
    "0.9\t0.64\t0.69\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
